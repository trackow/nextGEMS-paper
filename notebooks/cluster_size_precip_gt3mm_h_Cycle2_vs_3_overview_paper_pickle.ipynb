{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quantitative-council",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import label\n",
    "from skimage.measure import regionprops\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from statsmodels.distributions.empirical_distribution import ECDF as ecdf\n",
    "from scipy.ndimage import label, binary_dilation\n",
    "from scipy import optimize\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "    \n",
    "plotdir = './plots/precip/'\n",
    "if not os.path.exists(plotdir):\n",
    "    os.makedirs(plotdir)  \n",
    "    \n",
    "#sns.set(font='Franklin Gothic Book',\n",
    "sns.set(rc={\n",
    " 'axes.axisbelow': False,\n",
    " 'axes.edgecolor': 'black',\n",
    " 'axes.facecolor': 'None',\n",
    " 'axes.grid': False,\n",
    " 'axes.labelcolor': 'black',#dimgrey\n",
    " 'axes.spines.right': False,\n",
    " 'axes.spines.top': False,\n",
    " 'figure.facecolor': 'white',\n",
    " 'lines.solid_capstyle': 'round',\n",
    " 'patch.edgecolor': 'black',\n",
    " 'patch.force_edgecolor': True,\n",
    " 'text.color': 'black',\n",
    " 'xtick.bottom': True,\n",
    " 'xtick.color': 'black',\n",
    " 'xtick.direction': 'out',\n",
    " 'xtick.top': False,\n",
    " 'ytick.color': 'black',\n",
    " 'ytick.direction': 'out',\n",
    " 'ytick.left': True,\n",
    " 'ytick.right': False})\n",
    "\n",
    "sns.set_context(\"notebook\", rc={\"font.size\":16,\"axes.titlesize\":20,\"axes.labelsize\":18})\n",
    "\n",
    "\n",
    "def label_cluster(cluster_mask, stencil=np.ones((1,1)), undilute=True):\n",
    "    \"\"\"\n",
    "    Find coherent clusters.\n",
    "    \n",
    "    Method to find and label coherent clusters.\n",
    "    The stencil can be used to count also masked points\n",
    "    which are not direct neighbours to the cluster.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    cluster_mask : array-like\n",
    "        Two dimensional binary array being True where a cluster\n",
    "        exists and False otherwise\n",
    "    \n",
    "    stencil : np.ones(N,N)\n",
    "        Kernel/stencil to check connectivities.\n",
    "        N should be uneven, because otherwise the stencil\n",
    "        is not centered\n",
    "    \n",
    "    undilute : boolean\n",
    "        If True (default), then only the original cluster_mask\n",
    "        positions are labeled, otherwise also the labels for the\n",
    "        diluted fieled are included\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cluster_labels : np.array, same shape as cluster_mask\n",
    "        Array where connected clusters are given one number starting at 1.\n",
    "        Background is 0.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    >>> a = np.array([[1., 0.,0, 0., 1.],\n",
    "       [1., 0., 0, 0., 0.],\n",
    "       [1., 0., 0, 1., 1.],\n",
    "       [1., 0, 0, 1., 1.]])\n",
    "    >>> label_cluster(a,stencil=np.ones((1,1)))\n",
    "    array([[1, 0, 0, 0, 2],\n",
    "       [1, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 3, 3],\n",
    "       [1, 0, 0, 3, 3]], dtype=int32)\n",
    "    >>> label_cluster(a,stencil=np.ones((3,3)), undilute=False)\n",
    "    array([[1, 1, 0, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1],\n",
    "       [1, 1, 1, 1, 1]], dtype=int32)\n",
    "    >>> label_cluster(a,stencil=np.ones((3,3)))\n",
    "        np.array([[1, 0, 0, 0, 0, 2],\n",
    "       [1, 0, 0, 0, 0, 0],\n",
    "       [1, 0, 0, 0, 2, 2],\n",
    "       [1, 0, 0, 0, 2, 2]], dtype=int32)\n",
    "    >>> label_cluster(a, stencil=np.array([[0,1,0],[1,1,1],[0,1,0]]),undilute=False)\n",
    "    array([[1, 1, 0, 0, 2, 2],\n",
    "       [1, 1, 0, 0, 2, 2],\n",
    "       [1, 1, 0, 2, 2, 2],\n",
    "       [1, 1, 0, 2, 2, 2]], dtype=int32)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.ndimage import label, binary_dilation\n",
    "    labels = label(cluster_mask, structure=stencil)[0]\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def calc_cluster_size(cluster_mask, cluster_labels,normalize=True):\n",
    "    \"\"\"\n",
    "    Calculate the cluster size\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    cluster_mask : array-like\n",
    "        Two dimensional binary array being True where a cluster\n",
    "        exists and False otherwise\n",
    "    \n",
    "    cluster_labels : np.array, same shape as cluster_mask\n",
    "        Array where connected clusters are given one number starting at 1.\n",
    "        Background is 0.\n",
    "    \n",
    "    normalize : boolean\n",
    "        If normalize is True (default) than the cluster size is\n",
    "        given as a fraction of the domain, otherwise it is\n",
    "        the count of clustery pixels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    cluster_size : float\n",
    "        Area or fraction of each single cluster\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.ndimage import sum as cluster_sum\n",
    "    sum = cluster_sum(cluster_mask,cluster_labels,\\\n",
    "                       np.unique(cluster_labels)[1::])\n",
    "    if normalize:\n",
    "        sum = sum/(cluster_mask.shape[0]*cluster_mask.shape[1])\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "equivalent-georgia",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n"
     ]
    }
   ],
   "source": [
    "# THIS STEP IS ONLY NECESSARY IF PICKLE IS NOT USED!!\n",
    "\n",
    "array_yea= [\"2020\"]\n",
    "array_mon= [\"01\",\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\"]#\n",
    "\n",
    "\n",
    "exp_list      = [\"4km_fesom\",\"ifs_cycle2_4km_tp\",\"9km_nemo\",\"ifs_cycle2_9km_tp\",\"9km_fesom\",\"ifs_cycle2_3km_tp\"]\n",
    "expid_list= [\"hzfy\",\"hqys\",\"hz9o\",\"hr2n\",\"hz9o\",\"hr0n\"]\n",
    "# FESOM family is red, NEMO family blue\n",
    "color_list    = [\"#ff0000\",\"#ff0000\",\"#0000ff\",\"#0000ff\",\"purple\",\"darkorange\"]\n",
    "# give IFS resolution only, FESOM/NEMO don't change from 25/5km\n",
    "name_list   = [\"Cycle 3, 4.4km, IFS-FESOM\",\"Cycle 2, 4.4km, IFS-FESOM\",\"Cycle 3, 9km, IFS-NEMO\",\"Cycle 2, 9km, IFS-NEMO\",\"Cycle 3, 9km, IFS-FESOM\",\"Cycle 2, 2.8km, IFS-FESOM\"]\n",
    "# Cycle 3 is solid, Cycle 2/1 dashed\n",
    "array_linestyle= [\"solid\",\"dashed\",\"solid\",\"dashed\",\"solid\",\"dashed\"]\n",
    "# main simulation is thicker to stand out\n",
    "array_linewidth= [2,1,1,1,1,1]\n",
    "\n",
    "#stencil = np.array([[0,1,0],[1,1,1],[0,1,0]])    \n",
    "stencil = np.array([[1,1,1],[1,1,1],[1,1,1]])\n",
    "\n",
    "cluster_size_all = {}\n",
    "cluster_size_all[0] = []\n",
    "cluster_size_all[1] = []\n",
    "cluster_size_all[2] = []\n",
    "cluster_size_all[3] = []\n",
    "cluster_size_all[4] = []\n",
    "cluster_size_all[5] = []\n",
    "cluster_size_GPM_all = []\n",
    "\n",
    "for (y,YEA) in enumerate(array_yea):\n",
    "   for (m,MON) in enumerate(array_mon):\n",
    "        print(MON)\n",
    "\n",
    "        file=f'/work/bm1235/u233156/observations/GPM_IMERG/GPM_IMERG_hourly_{YEA}_{MON}_tropics.nc'\n",
    "        Pr = xr.open_dataset(file,engine='netcdf4')['precipitationCal'].load()\n",
    "        Pr.values = Pr.values\n",
    "        Pr_99_1_0=np.where(Pr > 3,1,0)\n",
    "        #num=0\n",
    "        dummy=[]\n",
    "        for t in range(len(Pr_99_1_0[:,0,0])):\n",
    "              cluster_labels = label_cluster(Pr_99_1_0[t,:,:], stencil)\n",
    "              #num=num+np.amax(cluster_labels)\n",
    "              dummy.extend(calc_cluster_size(Pr_99_1_0[t,:,:], cluster_labels, normalize=False))\n",
    "        cluster_size_GPM_all.extend(dummy)\n",
    "            \n",
    "        for (a,exp),expid in zip(enumerate(exp_list),expid_list): \n",
    "            if  array_linestyle[a] == \"solid\":  \n",
    "              file=f'/work/bm1235/u233156/IFS_cycle3/{exp}/{expid}_2D_precip_hourly_remap_0.1x0.1_{YEA}{MON}_tropics.nc'\n",
    "              Pr = xr.open_dataset(file,engine='netcdf4')['tp'].load()\n",
    "              Pr.values = Pr.values\n",
    "            else:\n",
    "              file=f'/work/bm1235/u233156/IFS_cycle2/tp_mmperd_{expid}_alltimes_remap_0.1x0.1_tropics_{YEA}{MON}.nc'\n",
    "              Pr = xr.open_dataset(file,engine='netcdf4')['var228'].load()\n",
    "              Pr.values = Pr.values /24 #from mm/d to mm/h                \n",
    "            Pr_99_1_0=np.where(Pr > 3,1,0)\n",
    "            #num=0\n",
    "            dummy=[]\n",
    "            for t in range(len(Pr_99_1_0[:,0,0])):\n",
    "              cluster_labels = label_cluster(Pr_99_1_0[t,:,:], stencil)\n",
    "              #num=num+np.amax(cluster_labels)\n",
    "              dummy.extend(calc_cluster_size(Pr_99_1_0[t,:,:], cluster_labels, normalize=False))\n",
    "            cluster_size_all[a].extend(dummy)\n",
    "            \n",
    "            \n",
    "# WRITE PICKLE\n",
    "\n",
    "# Open a file and use dump()\n",
    "with open('../data/cluster_size_precip_gt3mm_h_Cycle2_vs_3.pickle', 'wb') as file:\n",
    "      \n",
    "    # A new file will be created\n",
    "    pickle.dump([cluster_size_GPM_all,cluster_size_all], file)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba8abc-059b-4755-98af-24621c0bfd1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONTINUE HERE IF PICKLE IS USED\n",
    "\n",
    "with open(f'../data/cluster_size_precip_gt3mm_h_Cycle2_vs_3.pickle', 'rb') as file:\n",
    "    # The protocol version used is detected automatically, so we do not\n",
    "    # have to specify it.\n",
    "    cluster_size_GPM_all,cluster_size_all = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee5ec1-2cf5-4802-b15a-a9bfd90089a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_list      = [\"4km_fesom\",\"ifs_cycle2_4km_tp\",\"9km_nemo\",\"ifs_cycle2_9km_tp\",\"9km_fesom\",\"ifs_cycle2_3km_tp\"]\n",
    "expid_list= [\"hzfy\",\"hqys\",\"hz9o\",\"hr2n\",\"hz9o\",\"hr0n\"]\n",
    "# FESOM family is red, NEMO family blue\n",
    "color_list    = [\"#ff0000\",\"#ff0000\",\"#0000ff\",\"#0000ff\",\"purple\",\"darkorange\"]\n",
    "# give IFS resolution only, FESOM/NEMO don't change from 25/5km\n",
    "name_list   = [\"Cycle 3, 4.4km, IFS-FESOM\",\"Cycle 2, 4.4km, IFS-FESOM\",\"Cycle 3, 9km, IFS-NEMO\",\"Cycle 2, 9km, IFS-NEMO\",\"Cycle 3, 9km, IFS-FESOM\",\"Cycle 2, 2.8km, IFS-FESOM\"]\n",
    "# Cycle 3 is solid, Cycle 2/1 dashed\n",
    "array_linestyle= [\"solid\",\"dashed\",\"solid\",\"dashed\",\"solid\",\"dashed\"]\n",
    "# main simulation is thicker to stand out\n",
    "array_linewidth= [2,1,1,1,1,1]\n",
    "\n",
    "#bins=np.array([50 * i for i in range(100)])\n",
    "bins=np.array([.9 *np.exp(.41*i) for i in range(100)])\n",
    "resol='0.1x0.1$^{\\circ}$, hourly'\n",
    "     \n",
    "plt.figure(figsize=(10,6))\n",
    "for (a,name),color,linestyle,linewidth in zip(enumerate(name_list),color_list,array_linestyle,array_linewidth): \n",
    "    hist,bins=np.histogram(cluster_size_all[a], bins=bins) \n",
    "    avg = \"%.1f\" % np.mean(cluster_size_all[a])\n",
    "    print(name)\n",
    "    print(len(cluster_size_all[a]))\n",
    "    plt.plot((bins[0:-1]+bins[1:])/2,hist*(bins[0:-1]+bins[1:])/2,label=f'{name}, avg: {avg}',color=color,linestyle=linestyle,linewidth=linewidth)\n",
    "hist,bins=np.histogram(cluster_size_GPM_all, bins=bins) \n",
    "print(len(cluster_size_GPM_all))\n",
    "avg = \"%.1f\" % np.mean(cluster_size_GPM_all)\n",
    "plt.plot((bins[0:-1]+bins[1:])/2,hist*(bins[0:-1]+bins[1:])/2,label=f'GPM IMERG, avg: {avg}',color=\"k\")   \n",
    "plt.xlabel('size')\n",
    "plt.ylabel('number * size')\n",
    "plt.title(f'P > 3 mm/h, 8-connectivity, {resol}, tropics, 01-08/2020')\n",
    "plt.xlim([1,10000])\n",
    "plt.xscale('log')\n",
    "plt.ylim([0,20000000])\n",
    "plt.legend()     \n",
    "plt.legend(frameon=False)    \n",
    "#sns.despine(left=True, bottom=True)\n",
    "ax = plt.gca()\n",
    "#ax.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "plt.tight_layout()\n",
    "plt.savefig(plotdir + f'cluster_size_distribution_number_times_size_8_connect_3mmph_NextGEMS_Cycle3_Cycle2_4km_9km_ICON_GPM_tropics_202001to08.pdf')       \n",
    "plt.savefig(plotdir + f'cluster_size_distribution_number_times_size_8_connect_3mmph_NextGEMS_Cycle3_Cycle2_4km_9km_ICON_GPM_tropics_202001to08.png') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab8c94-57a9-42aa-a419-f2cd304a509d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/unstable",
   "language": "python",
   "name": "python3_unstable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
